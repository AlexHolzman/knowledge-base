---
metaTitle: Особенности платформы Deckhouse в Kubernetes
metaDescription: Платформа Deckhouse для Kubernetes - полный обзор возможностей, структуры, управления кластерами и интеграции. Читайте о развертывании и ключевых фишках.
author: Олег Марков
title: Особенности платформы Deckhouse в Kubernetes
preview: Узнайте, в чем отличия Deckhouse для Kubernetes, как развертывать платформу, управлять обновлениями, интегрировать с другими сервисами. Инструкции, структура, примеры и разбор архитектуры.
---

## Введение

Deckhouse — это современная платформа для управления и эксплуатации Kubernetes-кластеров, созданная для быстрого и безопасного внедрения облачных решений. Если перед вами стоит задача развернуть и поддерживать production-ready Kubernetes, платформа Deckhouse предложит удобные инструменты автоматизации и мониторинга, гибкое управление инфраструктурой и поддержку российских и международных облаков.

В этой статье вы познакомитесь с особенностями архитектуры Deckhouse, научитесь ее устанавливать и использовать, а также разберетесь в ключевых возможностях платформы. Вы увидите, чем Deckhouse отличается от остальных решений, и поймете, почему ее стоит выбрать для корпоративных задач.

## Архитектура и основные компоненты Deckhouse

### Deckhouse как Kubernetes Operator

Deckhouse — это, прежде всего, Kubernetes Operator, который работает внутри кластера. Operator не только управляет системными настройками, обновлениями компонентов, но и предоставляет удобный API для расширения.

#### Пример архитектурной схемы

- Deckhouse Controller (Operator), который периодически применяет актуальные значения для кластера, следя за соответствием инфраструктуры заявленным спецификациям.
- Модули Deckhouse расширяют функционал кластера, предоставляя поддержку облаков, мониторинг, сетевые политики и др.
- User modules — пространство для расширения платформы под свои требования.

### Модули Deckhouse

Платформа поставляется с большим количеством готовых модулей. Каждый модуль — это самостоятельный компонент, который можно включать и настраивать через Custom Resource Definitions (CRD).

#### Типичные модули

- **cloud-provider-aws/azure/gcp/yandex** — автоматизация работы с облаками.
- **cert-manager** — автоматизация работы с сертификатами и PKI.
- **prometheus, grafana** — мониторинг.
- **ingress-nginx** — балансировка трафика и web-прокси.
- **cni-cilium/flannel** — сетевые драйверы.
- **vertical-pod-autoscaler** — автоматическое масштабирование ресурсов.

Посмотрите на пример описания CRD для модуля lb-nginx:

```yaml
apiVersion: deckhouse.io/v1
kind: IngressNginxController
metadata:
  name: example
spec:
  ingressClass: nginx
  controller:
    replicas: 2
    service:
      type: LoadBalancer # Тип сервиса для балансировки входящего трафика
```

Каждый модуль поддерживает валидацию конфигурации и автодокументацию через `deckhouse documentation`.

### Roller — механизм обновлений

Deckhouse следит за актуальностью версий компонентов. Благодаря Roller, обновления мастеров, рабочих нод и приложения в кластере проходят по частям, с соблюдением стратегий обновления (например, maxUnavailable).

- Все обновления происходят через управляющий pod Deckhouse.
- Поддерживаются безопасные, атомарные обновления без падений кластера.
- Можно настраивать ручной или автоматический rollout.

### Управление инфраструктурой как кодом

Deckhouse поддерживает декларативное описание инфраструктуры. Описания хранятся в Git-репозитории, поддерживаются через CRD.

Пример описания worker group:

```yaml
apiVersion: deckhouse.io/v1
kind: NodeGroup
metadata:
  name: main-workers
spec:
  nodeTemplate:
    labels:
      node-role.deckhouse.io/main: ""
  replicas: 3 # Количество рабочих нод
  cloudInstances:
    classReference:
      name: default
      kind: AWSInstanceClass
```

Здесь вы описываете нужные группы серверов и их параметры. Deckhouse обработает описание и приведет кластер в соответствие с ним.

### Deckhouse Web-интерфейс и CLI

Deckhouse предоставляет веб-интерфейс и cli-инструментарий для управления модулями, обновлениями, просмотром логов, мониторингом состояния.

- `deckhouse-controller` и web UI можно развернуть опционально.
- CLI доступен через бинарник или docker-образ.

Основные команды CLI:

```sh
dhctl bootstrap --config=cluster.yaml    # Старт кластера по yaml-описанию
dhctl bootstrap-phase                   # Запуск отдельных фаз развертывания
dhctl status                            # Проверка статуса операций Deckhouse
```

### Безопасность, обновления, поддержка

- Deckhouse вендорит образы и независим от внешних регистров — это важно для ограниченных или импортонезависимых сред.
- Автоматические обновления CVE-critical компонентов.
- Разграничение доступа по ролям.
- Собственная PKI и интеграция с внешними системами авторизации.
- Встроенная поддержка внешних SIEM, журналирование, аудит.

## Установка и развертывание Deckhouse

### Шаг 1. Подготовка инфраструктуры

Вам понадобится доступ к готовым vm или облачной инфраструктуре (AWS, Yandex, VK Cloud, OpenStack, bare-metal).

В минимальном случае подготовьте:

- 1 master сервер (от 4 vCPU, 8GB RAM);
- 2-3 worker-сервера;
- Сетевой доступ между серверами;
- Домен для ingress и адрес для API.

### Шаг 2. Определение структуры кластера

Описываете желаемое состояние в едином yaml-файле. Пример:

```yaml
apiVersion: deckhouse.io/v1
kind: ClusterConfiguration
cloud:
  prefix: mycompany
  provider: Yandex
kubernetesVersion: "1.27"
```

### Шаг 3. Bootstrap-кластера

Используйте CLI-инструментарий dhctl.

```sh
dhctl bootstrap --config=cluster.yaml
```

- Deckhouse развернет control-plane, настроит worker-ноды.
- Создаст дефолтные модули (cni, monitoring, ingress).
- Установит Dashboard и выдаст kubeconfig.

### Шаг 4. Включение и настройка модулей

Для включения модуля воспользуйтесь CRD и примените его через kubectl или через систему управления GitOps.

```sh
kubectl apply -f module-monitoring.yaml
```

Пакетная установка модулей реализуется через deckhouse-контроллер.

### Шаг 5. Мониторинг, обновления, аудит

- Мониторинг и алерты настраиваются через prometheus/grafana.
- Безопасность — через policy-модули (например, pod-security-policy).
- Обновления можно производить через Web/CLI — управление стратегиями (max unavailable, поэтапные).

## Ключевые особенности, отличающие Deckhouse

### 1. Russian-friendly и интеграция с российскими облаками

Deckhouse поддерживает "из коробки" российские сервисы (Yandex.Cloud, VK Cloud, Selectel), а также интеграцию с популярными зарубежными провайдерами.

### 2. Полная автономность дистрибутива

- Встроенные реестры образов (можно разворачивать в air-gapped).
- Возможность работать на импортозамещенном ПО.
- Нет зависимости от облачных компонентов Microsoft, Google и др.

### 3. Гибкость: работа и на bare-metal, и в облаках

- Автоматизация provision/scale инфраструктуры в public/private clouds.
- Поддержка физических серверов и гибридных топологий.

### 4. Многоуровневое обновление и rollback

- Минимизация простоя сервисов — обновления идут по группам.
- Возможность быстро вернуть кластер к стабильному состоянию.

Шаблон rollout-стратегии может выглядеть так:

```yaml
apiVersion: deckhouse.io/v1
kind: DeckhouseRelease
metadata:
  name: deckhouse-v1.53.0
spec:
  rollout:
    maxUnavailable: 25% # не более 25% нод одновременно
    partitions: 2       # количество групп по которым идет обновление
```

### 5. Многоуровневая безопасность и поддержка комплаенса

- Все секреты хранятся только на master-нодах.
- Внутри — интеграция с HashiCorp Vault, поддержка kubernetes-rbac, сетевых политик и аутентификации через сторонние IdP.

### 6. GitOps-подход

Deckhouse поддерживает полное описание конфигураций инфраструктуры через git, а разворачивание и откаты контролируются из централизованного хранилища.

#### Пример внедрения GitOps для node groups

```yaml
apiVersion: deckhouse.io/v1
kind: NodeGroup
metadata:
  name: app-nodes
spec:
  replicas: 5
  cloudInstances:
    classReference:
      name: performance
      kind: YandexInstanceClass
```

После коммита yaml-файла в git, Deckhouse применит изменения, приведет фактическую инфраструктуру к нужному виду.

### 7. Расширяемость за счет пользовательских модулей

Можно создавать собственные модули на основе Deckhouse SDK. Это упрощает интеграцию с корпоративными системами.

Пример структуры пользовательского модуля:

```
deckhouse/
  modules/
    my-module/
      templates/
      hooks/
      values.yaml
```

Добавляете модуль в список, включаете его через CRD, и дальше управляете как встроенными.

### 8. Локализация и поддержка

- Документация и поддержка на русском языке.
- Поддержка мультикластерных установок и централизованное управление кластерами.

## Использование Deckhouse в production: Лучшие практики

### Использование RBAC и ограничение прав

Deckhouse поддерживает гибкие настройки RBAC. Например, можно создать группу операторов только с доступом к мониторингу:

```yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: monitoring
  name: monitoring-readonly
rules:
- apiGroups: [""]
  resources: ["pods", "services"]
  verbs: ["get", "list", "watch"]
```

### Защита каналов связи

Используйте встроенный cert-manager для автоматической выдачи сертификатов между компонентами.

### Настройка резервного копирования

Рекомендуется включить модуль backup-manager для регулярного бэкапа системных и пользовательских данных.

### Схемы обновления: Canaries, blue-green

Deckhouse-модули позволяют реализовать сложные сценарии обновления микросервисов: частичные rollout, откаты, тестовые среды.

### Автоматизация провижининга через внешний API

Автоматизируйте управление нодами через externals API Deckhouse (dhctl) или управляйте кластерами через платформенные инструменты.

## Заключение

Deckhouse — это зрелая и гибкая платформа для управления Kubernetes-кластерами, идеально подходящая для российского рынка и автономных корпоративных установок. Она ориентирована на полную автоматизацию жизненного цикла инфраструктуры, безопасную эксплуатацию, интеграцию с различными облаками и корпоративными инструментами.

Особенности платформы позволяют быстро развертывать кластеры в любых средах (облака, bare-metal), централизованно управлять масштабированием, обновлениями, аудитом и обеспечивать высокий уровень безопасности на всех уровнях. Ее архитектура "инфраструктура как код" облегчает внедрение DevOps-практик и интеграцию с системами CI/CD.

Платформа непрерывно развивается, поддерживает локализацию и эффективно закрывает все основные требования к продвинутому Kubernetes-окружению.

## Частозадаваемые технические вопросы по теме статьи и ответы на них

### Как переместить кластер Deckhouse между доступными облачными платформами без потери данных?

Для миграции кластера между облаками нужно:
1. Создать новое описание кластера с нужным cloud provider.
2. Выполнить резервное копирование etcd и persistent volumes (через модуль backup-manager).
3. Развернуть новый кластер с аналогичной сетевой и storage-конфигурацией.
4. Восстановить etcd и persistent volumes из бэкапов.
5. Провести проверку и перенести рабочие нагрузки.

### Как добавить кастомный модуль, не предусмотренный в стандартной поставке Deckhouse?

- Используйте Deckhouse SDK для генерации структуры модуля.
- Оформите необходимые hooks и values.yaml.
- Поместите модуль в каталог `deckhouse/modules`.
- Включите модуль через CRD, описав его настройки в Kubernetes.

### Как работает обновление ядра Kubernetes в Deckhouse? Можно ли управлять версией вручную?

Да, после появления новой версии Deckhouse автоматически предложит обновление через Web-интерфейс, CLI или CRD. При необходимости вы можете зафиксировать мажорную версию или отменить обновление, указав нужную версию в настройках ClusterConfiguration.

### Как интегрировать Deckhouse с внешней системой CI/CD?

- Экспортируйте сервисные kubeconfig.
- Создайте сервис-аккаунты с нужными правами.
- Настройте пайплайны для работы с K8s API (deploy/rollback).
- Используйте webhook-нотификации от Deckhouse для запуска CI/CD процессов.

### Как обеспечить резервное копирование Deckhouse и его компонентов?

Включите встроенный модуль backup-manager, настройте хранилище в S3 или аналогичном сервисе. Проверьте расписание и валидацию бэкапов через Web или CLI. Восстановление производится через штатные процедуры восстановления данных Kubernetes (restore hooks, импорт etcd и storage).

