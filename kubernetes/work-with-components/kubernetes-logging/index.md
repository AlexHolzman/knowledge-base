---
metaTitle: Использование логирования в Kubernetes
metaDescription: В этой статье вы узнаете как реализовать и настроить логирование в Kubernetes - разберем типы логов, лучшие практики, инструменты сбора и поиска, примеры конфигурации и часто задаваемые вопросы
author: Олег Марков
title: Использование логирования в Kubernetes
preview: Узнайте как организовать логирование в Kubernetes - научитесь собирать, анализировать и искать логи из контейнеров с помощью современных инструментов и практик
---

## Введение

Работая с Kubernetes, вы сталкиваетесь с большим количеством компонентов, сервисов и приложений, работающих в кластере. Для эффективной диагностики, поиска и решения проблем крайне важно организовать грамотное логирование ваших приложений и самого Kubernetes. Лог-файлы позволяют оперативно отслеживать ошибки, аномалии и получать информацию о работе сервисов, без которых поддержка современной инфраструктуры невозможна.

Давайте посмотрим, какие типы логирования вы можете встретить в кластере Kubernetes, какой подход лучше выбрать для архитектуры сбора логов, как их централизировать, визуализировать и анализировать. Все нюансы – от стандарта `stdout/stderr` до интеграции с такими системами как ELK (Elasticsearch, Logstash, Kibana), Loki, Fluentd и другими популярными инструментами – разберём на понятных примерах и с подробными пояснениями.

## Что такое логирование в Kubernetes

Логирование в Kubernetes – это процесс сбора, хранения и анализа сообщений от запущенных контейнеров, самих компонентов Kubernetes (kubelet, apiserver, controller-manager и др.), а также системных логов узлов (нод). Лог-файлы используются для мониторинга, отладки, аудита и автоматизации задач управления кластером.

Ключевой особенностью Kubernetes является то, что контейнеры зачастую являются "эфемерными" – перезапускаются, переезжают между нодами, и у них нет постоянной файловой системы. Поэтому логирование отличается по сравнению с традиционным миром монолитных приложений.

## Типы логов в Kubernetes

### Логи контейнеров

Когда вы запускаете приложение внутри контейнера, стандартной практикой является вывод логов в стандартные потоки вывода (`stdout`) и ошибок (`stderr`). Смотрите, что происходит: Docker (или другой контейнер-рантайм) захватывает этот вывод и сохраняет его в файлы на хосте (например, в `/var/log/containers`). Затем Kubernetes или сторонние инструменты могут собирать эти файлы для дальнейшего анализа.

**Пример логирования в Go-приложении:**

```go
// Этот код выводит сообщение в стандартный поток вывода
log.Println("Service started successfully")
```

**Важно:** Не рекомендуется писать логи с привязкой к локальным файлам внутри контейнера (например, `/app/logs/service.log`), потому что эти файлы исчезнут при удалении или перезапуске контейнера.

### Логи узлов (нод)

На каждой виртуальной или физической машине (ноде), которую использует ваш кластер, имеются собственные системные логи. Примеры:

- `/var/log/messages` (общесистемные логи)
- `/var/log/syslog` (в системах на основе Debian/Ubuntu)
- `/var/log/kubelet.log` (лог kubelet-агента)

Эти логи играют вспомогательную роль, чаще используются администраторами для диагностики системного уровня.

### Логи компонентов кластера

Kubernetes сам по себе состоит из различных сервисов и компонентов, каждый из которых хранит свои журналы:

- kube-apiserver
- kube-controller-manager
- kube-scheduler
- etcd

Сообщения этих сервисов формируют важный слой для анализа и аудита работы кластера.

### События Kubernetes

Не стоит путать логи с эвентами. События (Events) – это специфические уведомления о важных изменениях состояния объектов кластера. Посмотреть их можно командой:

```bash
kubectl get events
```

Эвенты важны для отслеживания нарушений, проблем старта подов, проблем с образами, но они не заменяют полноценных логов.

## Лучшие практики логирования в Kubernetes

### 1. Всегда выводите логи в stdout/stderr

Поскольку контейнеры могут быть пересозданы или перемещены, не используйте локальные файлы для логирования. Все современные системы сбора логов поддерживают захват стандартного вывода, поэтому просто пишите:

```javascript
console.log('App started')
// Или для ошибок:
console.error('Error occurred')

// В Python:
print("Started processing task")
import sys
print("Error in processing", file=sys.stderr)
```

Вы облегчаете себе последующую интеграцию с инфраструктурой логирования.

### 2. Используйте структурированное логирование

Структурированные логи (обычно в формате JSON) позволяют делать более сложный поиск и фильтрацию. Например, в Go:

```go
log.Printf(`{"level":"info","msg":"Order created","order_id":%d,"user_id":%d}`, 1234, 567)
```

Аналогично для Node.js/Python можно использовать форматтеры, которые выводят логи в виде JSON-объектов.

### 3. Настройте агрегатор логов

Развернутый кластер производит огромное количество логов; собирать их централизованно – мастхэв. Стандартные инструменты:

- **Fluentd**
- **Logstash**
- **Loki (от Grafana Labs)**
- **Filebeat**
- **Vector**

С их помощью вы можете буквально "тащить" логи со всех узлов, фильтровать, перекидывать в базы логов (Elasticsearch, S3, Kafka) и просматривать через удобные веб-интерфейсы.

### 4. Учитывайте ротацию и хранение логов

Лог-файлы могут быстро вырасти до гигантских размеров. Kubernetes сам управляет ротацией контейнерных логов, например, на базовом уровне Docker:

- по умолчанию сохраняет до 10 файлов по 10 МБ (можно менять параметры через `/etc/docker/daemon.json`).

Ротация логов на хосте нужна, чтобы не "забить" диск старым мусором.

## Способы сбора логов в Kubernetes

### Sidecar-контейнер для логирования

Один из популярных паттернов: в каждый Pod добавляете отдельный контейнер (sidecar), который занимается сбором и отправкой логов. Очень удобно, если вам нужно логировать специфические данные, объединять несколько потоков логов или парсить нестандартные форматы.

**Пример Pod-манифеста с sidecar:**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: logger-demo
spec:
  containers:
  - name: app
    image: your-app
    volumeMounts:
    - name: logs
      mountPath: /logs
  - name: log-shipper
    image: fluentd
    volumeMounts:
    - name: logs
      mountPath: /logs
  volumes:
  - name: logs
    emptyDir: {}
```

Здесь оба контейнера имеют доступ к общей директории `/logs`. Sidecar собирает логи, которые ваш основной контейнер пишет туда (если без `stdout`, но лучше не замыкать только на этом способе).

### Демон-сеты для сбора логов

Классическая схема – на каждую ноду разворачивается демонсет, например, с Fluentd, Filebeat, Vector или Logagent. Демонсет в Kubernetes – это POD, запускаемый на каждой (или выбранных) ноде.

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: fluentd
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd:v1.13
        resources:
          limits:
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
```

Этот способ прозрачен для ваших приложений – они просто пишут логи в stdout, а демонсет собирает файлы на каждой машине и пересылает их дальше.

### Сбор логов из stdout/stderr

Ручным способом можно просмотреть логи любого пода:

```bash
kubectl logs podname
```

Для получения логов всех контейнеров в POD:

```bash
kubectl logs podname -c containername
```

Для "живого" просмотра (фолловинг):

```bash
kubectl logs -f podname
```

Для поиска логов только за последний запуск, особенно если контейнер перезапускался:

```bash
kubectl logs --previous podname
```

## Архитектура централизованного логирования

Когда логов много и они нужны для анализа, не обойтись без централизованных решений. Принятые схемы:

- **Логи собираются с каждой ноды** (через демонсет), отправляются в брокер (например, Kafka или Logstash), затем в систему хранения и поиска (часто Elasticsearch).
- **Визуализация через Kibana, Grafana, Loki** – при этом поиск делается мгновенным и удобным.
- **Хранение** логов регулируется политиками – старые логи архивируются или удаляются.

**Совет:** обращайте внимание на аутентификацию и контроль доступа к логам – там могут содержаться чувствительные данные.

## Примеры популярных систем централизованного логирования

### ELK Stack (Elasticsearch, Logstash, Kibana)

- **Elasticsearch** – индексирует и хранит данные логов.
- **Logstash** – агрегирует, фильтрует и трансформирует логи.
- **Kibana** – для просмотра, визуализации и анализа.

**Базовый пайплайн:**

1. Приложения выводят логи в stdout.
2. Filebeat или Fluentd (через демонсет) читает логи на ноде.
3. Отправляет их в Logstash/Elasticsearch.
4. Просмотр через Kibana.

### Loki и Grafana

- **Loki** – современное решение для скалируемого сбора и поиска логов (аналогично Prometheus, только для логов).
- **Grafana** – отображает, фильтрует и анализирует логи.

Loki легче и проще в поддержке, меньше ресурсов (не строит индексы, как Elasticsearch), быстро внедряется в Kubernetes через Helm чарты.

### Другие инструменты

- **Graylog** – распространяемый, поддерживает UDP и GELF форматы.
- **Splunk** – платформа для enterprise-auditing, мощный анализатор.
- **Sentry** – часто используется для логирования ошибок (но не полной лог-агрегации).

## Тонкости интеграции и отладки логирования

### Использование аннотаций и метаданных

Система агрегирования может добавлять к логам информацию о namespace, поде, контейнере, label – чтобы вы могли находить нужный лог по любому признаку.

### Обработка мультинейминга (мульти-контейнерных подов)

В логах появляется дополнительное поле "container_name". Пример структурированного лога с помощью Filebeat:

```json
{
  "log": "User has logged in",
  "kubernetes": {
    "container_name": "app",
    "namespace_name": "production",
    "pod_name": "my-app-5468f4fcf6-jtk37"
  }
}
```

### Логирование на уровне ingress-контроллеров

Иногда вы захотите получить доступ к логам входящего трафика. Большинство ingress-контроллеров (Nginx Ingress, Traefik) поддерживают свой формат логирования. Обыщайте их документацию для настройки.

## Пример развертывания централизованного логирования с помощью Helm

Helm позволяет быстро развернуть такие решения как Loki или ELK.

**Команда для установки Loki:**

```bash
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update
helm install loki grafana/loki-stack --namespace=loki --create-namespace
```

**Команда для установки ELK (Elasticsearch, Kibana, Filebeat):**

```bash
helm repo add elastic https://helm.elastic.co
helm install elasticsearch elastic/elasticsearch --namespace=logs --create-namespace
helm install kibana elastic/kibana --namespace=logs
helm install filebeat elastic/filebeat --namespace=logs
```

**Не забудьте настроить политики доступа, ротацию и ресурсы!**

## Мониторинг и алертинг на основе логов

Не ограничивайтесь только просмотром логов — подключайте алертинг! Очень распространенная практика – ставить триггеры (например, на HTTP 500 ошибок) и получать уведомления (Slack, Telegram, email).

В Grafana Alerts или ElastAlert (для ELK) можно задать выражения, по которым система "поднимает тревогу".

---

В итоге, Kubernetes предлагает гибкую и мощную основу для построения системы логирования. Вы не ограничены одним инструментом или схемой сбора – инфраструктуру можно и нужно адаптировать под размеры и задачи вашего бизнеса. Главное – не полагаться на логи, локализованные в контейнере, и заранее строить централизованную, отказоустойчивую схему.

## Частозадаваемые технические вопросы по теме статьи и ответы на них

### Как получить логи всех подов в одном namespace?

Вы можете использовать такой однострочник:
```bash
for p in $(kubectl get pods -n my-namespace -o name); do
  kubectl logs -n my-namespace $p;
done
```
Это выведет последовательность логов от всех подов в выбранном namespace.

### Как видеть логи уже удаленного pod, если контейнер перезапустился?

Kubernetes сохраняет логи только для текущих и предыдущих контейнеров (при рестарте). Если под был удалён, его логи теряются. Чтобы этого избежать, настройте централизованный сбор логов через демонсет (Fluentd, Filebeat, Loki), который пишет логи в базу или в облако.

### Что делать если логи не выводятся командой kubectl logs?

Проверьте, не завершился ли контейнер мгновенно после запуска. Если да — используйте флаг `--previous` для просмотра логов предыдущей инстанции. Также убедитесь, что контейнер вообще выводит логи в stdout/stderr и не пишет их только во внутренние файлы.

### Как ограничить размер логов на ноде и сделать их ротацию?

Для Docker настройте файл `/etc/docker/daemon.json`:
```json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  }
}
```
Перезапустите Docker: `systemctl restart docker`.
Для других рантаймов (containerd, CRI-O) аналогичные опции ищите в их документации.

### Можно ли фильтровать логи по ключевым словам прямо в kubectl logs?

Да, используйте команду grep:
```bash
kubectl logs podname | grep "ERROR"
```
Для постоянного "живого" просмотра нескольких строк используйте `kubectl logs -f podname | grep "pattern"`.