---
metaTitle: Развертывание Airflow в Docker
metaDescription: Узнайте как развернуть Apache Airflow в Docker используя контейнеризацию для управления рабочими процессами независимо от инфраструктуры
author: Ольга Смирнова
title: Развертывание Airflow в Docker
preview: Разверните Apache Airflow в Docker для удобного управления сложными рабочими процессами - простое руководство и примеры помогут вам начать быстро и уверенно
---

## Введение

Apache Airflow – это платформа с открытым исходным кодом для автоматизации, составления и мониторинга рабочих процессов. Она чрезвычайно удобна для управления сложными процессами обработки данных и используется в различных отраслях для автоматизации рутинных задач. Одним из популярных способов развертывания Apache Airflow является использование Docker, который позволяет изолировать приложение и его зависимости в контейнере, обеспечивая портативность и легкость управления.

В этой статье мы рассмотрим, как развернуть Airflow в Docker, чтобы вы могли эффективно управлять рабочими процессами независимо от инфраструктуры. Мы погрузимся в детали настройки и посмотрим, как Airflow функционирует в контейнизированной среде.

## Конфигурация и установка Docker

### Установка Docker

Прежде чем приступить к развертыванию Airflow, вам необходимо убедиться, что у вас установлен Docker. Docker позволяет запускать приложения в изолированных контейнерах.

1. **Установка Docker на Ubuntu:**

   ```bash
   sudo apt-get update
   sudo apt-get install docker-ce docker-ce-cli containerd.io
   ```

2. **Проверка установки Docker:**

   После установки Docker, проверьте, работает ли он, выполнив команду:

   ```bash
   docker --version
   ```

   Эта команда должна вывести текущую версию Docker, что подтверждает успешную установку.

### Установка Docker Compose

Docker Compose упрощает запуск мультимодульных контейнеров. Airflow обычно требует множества сервисов, и Docker Compose идеален для управления ими.

1. **Установка Docker Compose:**

   ```bash
   sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
   sudo chmod +x /usr/local/bin/docker-compose
   ```

2. **Проверка установки Docker Compose:**

   Вы можете проверить успешность установки следующей командой:

   ```bash
   docker-compose --version
   ```

   Она должна вывести версию Docker Compose.

## Настройка Airflow с использованием Docker Compose

### Структура папок и файлов

Для начала работы создадим базовую структуру директорий и файлов, необходимых для запуска Airflow в Docker.

1. Создайте новую директорию, в которой будет размещена конфигурация Airflow:

   ```bash
   mkdir airflow-docker
   cd airflow-docker
   ```

2. Создайте файл `docker-compose.yml`, который будет содержать конфигурацию для Docker Compose:

   ```yaml
   version: '3'
   services:
     postgres:
       image: postgres:13
       environment:
         POSTGRES_USER: airflow
         POSTGRES_PASSWORD: airflow
         POSTGRES_DB: airflow
       
     webserver:
       image: apache/airflow:2.2.2
       depends_on:
         - postgres
       environment:
         AIRFLOW__CORE__EXECUTOR: LocalExecutor
         AIRFLOW__CORE__SQL_ALCHEMY_CONN: 'postgresql+psycopg2://airflow:airflow@postgres/airflow'
         AIRFLOW__CORE__LOAD_EXAMPLES: 'true'
       volumes:
         - ./dags:/opt/airflow/dags
         - ./logs:/opt/airflow/logs
         - ./plugins:/opt/airflow/plugins
       ports:
         - "8080:8080"
   ```

Как видите, мы используем PostgreSQL в качестве бэкэнда базы данных и Airflow Webserver для доступа к интерфейсу Airflow.

### Инициализация базы данных

Перед началом работы с Airflow необходимо инициализировать базу данных. Делается это с помощью следующей команды:

```bash
docker-compose up airflow-init
```

Эта команда создаст начальные таблицы в базе данных, необходимые для работы Airflow.

### Запуск сервиса Airflow

Теперь, когда база данных инициализирована, мы можем запустить все сервисы:

```bash
docker-compose up
```

После этой команды Docker Compose начнет копировать образы и запустить сервисы на основе конфигурации в файле `docker-compose.yml`.

## Проверка развертывания

### Доступ к интерфейсу Airflow

После успешного старта контейнеров вы сможете получить доступ к веб-интерфейсу Airflow, введя в браузере следующий адрес:

```
http://localhost:8080
```

На этой странице будет отображена панель управления Airflow, где вы сможете наблюдать за состоянием ваших DAG (Directed Acyclic Graph), а также управлять их выполнением. Если вы видите главную страницу Airflow, значит развертывание было успешным.

### Мониторинг работы контейнеров

Docker предоставляет удобные средства для мониторинга работы контейнеров. Вы можете использовать следующую команду для просмотра логов:

```bash
docker-compose logs
```

Эта команда выведет текущие логи всех контейнеров, что очень удобно для устранения неполадок или просто для понимания того, что происходит внутри контейнеров.

## Заключение

Развертывание Apache Airflow с использованием Docker предоставляет множество преимуществ, включая простоту развертывания, масштабируемость и легкость управления зависимостями. Использование Docker Compose делает процесс более удобным, особенно когда у вас много сервисов и зависимостей.

Мы разобрали основные шаги по установке и первичной настройке Airflow в контейнерах: начиная от установки Docker и Docker Compose, до развертывания и тестирования работы Airflow. Теперь вы можете использовать эту платформу для управления и автоматизации ваших рабочих процессов, имея гибкость и надежность, предоставляемую контейнерами.